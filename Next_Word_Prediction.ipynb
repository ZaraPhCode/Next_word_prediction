{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qGt287g3d7A"
      },
      "source": [
        "# Next_Word_prediction\n",
        "\n",
        "### By: ZaraPhCode\n",
        "\n",
        "Here is the code that uses a file containing texts with different topics, and design an LSTM Neural Network to predict the next word in a sequence. \n",
        "\n",
        "I got some help from this Source especially with the dataset:\n",
        "\n",
        "[link text](https://www.geeksforgeeks.org/next-word-prediction-with-deep-learning-in-nlp/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0H84N_h93Gp_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import regex as re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we define a function to open a text file and remove unneccessary characters. Then we transform this list of words into a categorial list in which any word has got an specific label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JTg61yQ43I36"
      },
      "outputs": [],
      "source": [
        "def file_to_sentence_list(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Splitting the text into sentences using\n",
        "    # delimiters like '.', '?', and '!'\n",
        "    sentences = [sentence.strip() for sentence in re.split(\n",
        "        r'(?<=[.!?])\\s+', text) if sentence.strip()]\n",
        "\n",
        "    return sentences\n",
        "\n",
        "file_path = '/content/sample_data/1661-0.txt'\n",
        "text_data = file_to_sentence_list(file_path)\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create input sequences\n",
        "input_sequences = []\n",
        "for line in text_data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences and split into predictors and label\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(\n",
        "    input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "\n",
        "# Convert target data to one-hot encoding\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Designing the LSTM network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_nCe2Tj23Vpi"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 10,\n",
        "                    input_length=max_sequence_len-1))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "fitting the network:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX8dD7YS3a8n",
        "outputId": "d632303a-de29-4810-8a3a-1680d5f3c8fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3312/3312 [==============================] - 98s 27ms/step - loss: 6.4967 - accuracy: 0.0642\n",
            "Epoch 2/50\n",
            "3312/3312 [==============================] - 45s 14ms/step - loss: 5.8042 - accuracy: 0.1033\n",
            "Epoch 3/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 5.4110 - accuracy: 0.1301\n",
            "Epoch 4/50\n",
            "3312/3312 [==============================] - 43s 13ms/step - loss: 5.1304 - accuracy: 0.1443\n",
            "Epoch 5/50\n",
            "3312/3312 [==============================] - 41s 13ms/step - loss: 4.8792 - accuracy: 0.1542\n",
            "Epoch 6/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 4.6525 - accuracy: 0.1646\n",
            "Epoch 7/50\n",
            "3312/3312 [==============================] - 43s 13ms/step - loss: 4.4468 - accuracy: 0.1755\n",
            "Epoch 8/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 4.2569 - accuracy: 0.1884\n",
            "Epoch 9/50\n",
            "3312/3312 [==============================] - 41s 13ms/step - loss: 4.0826 - accuracy: 0.2014\n",
            "Epoch 10/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 3.9219 - accuracy: 0.2173\n",
            "Epoch 11/50\n",
            "3312/3312 [==============================] - 40s 12ms/step - loss: 3.7724 - accuracy: 0.2346\n",
            "Epoch 12/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 3.6390 - accuracy: 0.2522\n",
            "Epoch 13/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 3.5139 - accuracy: 0.2698\n",
            "Epoch 14/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 3.4013 - accuracy: 0.2859\n",
            "Epoch 15/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 3.2983 - accuracy: 0.3002\n",
            "Epoch 16/50\n",
            "3312/3312 [==============================] - 40s 12ms/step - loss: 3.2054 - accuracy: 0.3149\n",
            "Epoch 17/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 3.1209 - accuracy: 0.3289\n",
            "Epoch 18/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 3.0412 - accuracy: 0.3422\n",
            "Epoch 19/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 2.9715 - accuracy: 0.3521\n",
            "Epoch 20/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 2.9031 - accuracy: 0.3637\n",
            "Epoch 21/50\n",
            "3312/3312 [==============================] - 40s 12ms/step - loss: 2.8423 - accuracy: 0.3748\n",
            "Epoch 22/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 2.7877 - accuracy: 0.3836\n",
            "Epoch 23/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 2.7346 - accuracy: 0.3935\n",
            "Epoch 24/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 2.6844 - accuracy: 0.4010\n",
            "Epoch 25/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 2.6405 - accuracy: 0.4087\n",
            "Epoch 26/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 2.5962 - accuracy: 0.4164\n",
            "Epoch 27/50\n",
            "3312/3312 [==============================] - 43s 13ms/step - loss: 2.5588 - accuracy: 0.4225\n",
            "Epoch 28/50\n",
            "3312/3312 [==============================] - 43s 13ms/step - loss: 2.5206 - accuracy: 0.4296\n",
            "Epoch 29/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 2.4885 - accuracy: 0.4347\n",
            "Epoch 30/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 2.4539 - accuracy: 0.4413\n",
            "Epoch 31/50\n",
            "3312/3312 [==============================] - 43s 13ms/step - loss: 2.4227 - accuracy: 0.4458\n",
            "Epoch 32/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 2.3978 - accuracy: 0.4508\n",
            "Epoch 33/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 2.3688 - accuracy: 0.4569\n",
            "Epoch 34/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 2.3465 - accuracy: 0.4595\n",
            "Epoch 35/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 2.3225 - accuracy: 0.4640\n",
            "Epoch 36/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 2.2995 - accuracy: 0.4700\n",
            "Epoch 37/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 2.2748 - accuracy: 0.4751\n",
            "Epoch 38/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 2.2542 - accuracy: 0.4783\n",
            "Epoch 39/50\n",
            "3312/3312 [==============================] - 41s 13ms/step - loss: 2.2383 - accuracy: 0.4793\n",
            "Epoch 40/50\n",
            "3312/3312 [==============================] - 43s 13ms/step - loss: 2.2171 - accuracy: 0.4835\n",
            "Epoch 41/50\n",
            "3312/3312 [==============================] - 41s 12ms/step - loss: 2.2016 - accuracy: 0.4852\n",
            "Epoch 42/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 2.1878 - accuracy: 0.4888\n",
            "Epoch 43/50\n",
            "3312/3312 [==============================] - 44s 13ms/step - loss: 2.1710 - accuracy: 0.4912\n",
            "Epoch 44/50\n",
            "3312/3312 [==============================] - 44s 13ms/step - loss: 2.1532 - accuracy: 0.4958\n",
            "Epoch 45/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 2.1398 - accuracy: 0.4967\n",
            "Epoch 46/50\n",
            "3312/3312 [==============================] - 43s 13ms/step - loss: 2.1302 - accuracy: 0.4992\n",
            "Epoch 47/50\n",
            "3312/3312 [==============================] - 42s 13ms/step - loss: 2.1131 - accuracy: 0.5017\n",
            "Epoch 48/50\n",
            "3312/3312 [==============================] - 44s 13ms/step - loss: 2.1051 - accuracy: 0.5032\n",
            "Epoch 49/50\n",
            "3312/3312 [==============================] - 43s 13ms/step - loss: 2.0908 - accuracy: 0.5057\n",
            "Epoch 50/50\n",
            "3312/3312 [==============================] - 43s 13ms/step - loss: 2.0873 - accuracy: 0.5063\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55df12b250>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X, y, epochs=50, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For having better result, 200 epochs and more is recommended.\n",
        "Lets see how our network perform after training for only 50 epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2-G3Jgp3dM5",
        "outputId": "0cd75b69-727e-4665-cf46-ce4e04ff2fc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "Next predicted words: Books are good for  some days or\n"
          ]
        }
      ],
      "source": [
        "# Generate next word predictions\n",
        "seed_text = \"Books are good for \"\n",
        "next_words = 3\n",
        "\n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences(\n",
        "\t\t[token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted_probs = model.predict(token_list)\n",
        "\tpredicted_word = tokenizer.index_word[np.argmax(predicted_probs)]\n",
        "\tseed_text += \" \" + predicted_word\n",
        "\n",
        "print(\"Next predicted words:\", seed_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Not bad!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNlrDrf08t_x"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
